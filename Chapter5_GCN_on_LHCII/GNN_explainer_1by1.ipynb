{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6c56f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "#from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GCNConv, GNNExplainer\n",
    "#from GNN_explainer_modified import *\n",
    "\n",
    "#This notebook is to test the pre-trained model with the test set.\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "\n",
    "from my_dataset_1by1 import *\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a26c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_regression_Net_single(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    feed the data one-by-one version.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, nhid1, nhid2, nhid3):\n",
    "        super(GCN_regression_Net_single, self).__init__()\n",
    "        self.conv1 = GCNConv(n_features, nhid1)\n",
    "        self.conv2 = GCNConv(nhid1, nhid2)\n",
    "        self.conv3 = GCNConv(nhid2, nhid3)\n",
    "        #self.bn = torch.nn.BatchNorm1d(n_nodes)\n",
    "        #self.dropout = dropout\n",
    "        #self.linear1 = torch.nn.Linear(nhid3, 1)    #used in previous patch, reduce nhid first\n",
    "        self.linear1 = torch.nn.Linear(nhid3, 1)\n",
    "        self.linear2 = torch.nn.Linear(508, 1)\n",
    "        #self.batch_size = batch_size\n",
    "        #self.maxpool = torch.nn.MaxPool2d(4, stride = 4) # max pooling with square window of size=3, stride=2\n",
    "        #no maxpooling because it will reduce the feature channel.\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x, edge_index, edge_weight = x, edge_index, edge_weight #X has shape[batch_size * n_node]\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_weight)    # X in shape: [n_nodes * batch_size, nhid3]\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = F.dropout(x, training=self.training) \n",
    "        \n",
    "        x = self.linear1(x) #output shape in [508,1]  \n",
    "        \n",
    "        #print(\"the output layer shape is:\")\n",
    "        #print(x.shape)\n",
    "        \n",
    "        \n",
    "        x = torch.squeeze(x)    #output shape in [508]\n",
    "        #print(type(x))\n",
    "        x = self.linear2(x) #output shape in [1]\n",
    "        x = torch.squeeze(x)\n",
    "        print(type(x))\n",
    "        #x = torch.reshape(x, (self.batch_size, -1)) # output shape in [batch_size, n_node]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91334fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_example(num):\n",
    "    with torch.no_grad():\n",
    "        datapoint = My_dataset().__getitem__(num)\n",
    "        print(\"True y is: %f\" %(datapoint.y))\n",
    "\n",
    "        x, edge_index, edge_weight = datapoint.X, datapoint.edge_index, datapoint.edge_attr\n",
    "        x, edge_index, edge_weight = Variable(torch.as_tensor(X, dtype=torch.float32)).to(device), edge_index.to(device), edge_weight.to(device)  \n",
    "        prediction = model(x, edge_index, edge_weight)\n",
    "    print(\"Prediction is: %f\" %(prediction))\n",
    "    return\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0313d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "torch.random.manual_seed(1)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "dataset_size = 3000\n",
    "perm = torch.randperm(dataset_size).numpy()\n",
    "partition = {}\n",
    "partition[\"train\"] = perm[:int(dataset_size*8/10)]\n",
    "partition[\"validation\"] = perm[int(dataset_size*8/10):int(dataset_size*9/10)]\n",
    "partition[\"test\"] = perm[int(dataset_size*9/10):]\n",
    "\n",
    "model = GCN_regression_Net_single(n_features = 6, \n",
    "                               nhid1 = 32, \n",
    "                               nhid2 = 64, \n",
    "                               nhid3 = 128).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1E-6, weight_decay=5e-4)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "earlystopping = True\n",
    "best_epoch_num = 0\n",
    "best_loss_valid = 1e10\n",
    "patient = 100\n",
    "prefix = \"gcn_net_trained_18_single_MSELoss\"\n",
    "max_epochs = 500\n",
    "    \n",
    "train_set = torch.utils.data.Subset(My_dataset(), partition[\"train\"])\n",
    "validation_set = torch.utils.data.Subset(My_dataset(), partition[\"validation\"])\n",
    "test_set = torch.utils.data.Subset(My_dataset(), partition[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd5d9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f99dd382",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gcn_net_trained_11_16batched_MSELoss.pt.final'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b4c91658a0f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mPATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gcn_net_trained_11_16batched_MSELoss.pt.final'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gcn_net_trained_11_16batched_MSELoss.pt.final'"
     ]
    }
   ],
   "source": [
    "PATH = 'gcn_net_trained_11_16batched_MSELoss.pt.final'\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da781aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method type of Tensor object at 0x0000029ADC028840>\n",
      "torch.Size([508, 6])\n",
      "<built-in method type of Tensor object at 0x0000029ADC028CC0>\n",
      "torch.Size([2, 41258])\n",
      "<built-in method type of Tensor object at 0x0000029ADAC84600>\n",
      "torch.Size([41258])\n",
      "<built-in method type of Tensor object at 0x0000029ADC03FFC0>\n",
      "torch.Size([])\n",
      "910.0\n"
     ]
    }
   ],
   "source": [
    "explainer = GNNExplainer(model, epochs=200)\n",
    "\n",
    "datapoint = next(iter(train_set))\n",
    "x, edge_index, edge_weight, y = datapoint.X, datapoint.edge_index, datapoint.edge_attr, datapoint.y\n",
    "x, edge_index, edge_weight = Variable(torch.as_tensor(x, dtype=torch.float32)).to(device), edge_index.to(device), edge_weight.to(device)\n",
    "y = Variable(torch.as_tensor(y, dtype=torch.float32)).to(device)\n",
    "            \n",
    "for item in (x, edge_index, edge_weight, y):\n",
    "    print(item.type)\n",
    "    print(item.shape)\n",
    "\n",
    "print(y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f86c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain node 100:   0%|                                                                        | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0b6da0df379e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnode_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnode_feat_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplain_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch_geometric\\nn\\models\\gnn_explainer.py\u001b[0m in \u001b[0;36mexplain_node\u001b[1;34m(self, node_idx, x, edge_index, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mlog_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__to_log_prob__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__loss__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch_geometric\\nn\\models\\gnn_explainer.py\u001b[0m in \u001b[0;36m__loss__\u001b[1;34m(self, node_idx, log_logits, pred_label)\u001b[0m\n\u001b[0;32m    128\u001b[0m         loss = -log_logits[\n\u001b[0;32m    129\u001b[0m             \u001b[0mnode_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnode_idx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlog_logits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 0, pred_label[0]]\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "node_idx = 100\n",
    "node_feat_mask, edge_mask = explainer.explain_node(node_idx, x, edge_index, edge_weight = edge_weight)\n",
    "ax, G = explainer.visualize_subgraph(node_idx, edge_index, edge_mask, y=y.item())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = -1\n",
    "gnode_feat_mask, gedge_mask = explainer.explain_graph(x, edge_index, edge_weight = edge_weight)\n",
    "ax, G = explainer.visualize_subgraph(node_idx, edge_index, gedge_mask, y=data.y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78051710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
